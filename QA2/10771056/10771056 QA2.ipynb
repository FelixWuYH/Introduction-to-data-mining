{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case 1 Entropy: 0.6854752972273344\n",
      "Case 2 Entropy: 0.8264662506490407\n",
      "Case 3 Entropy: 0.6896596952239761\n",
      "The best clustering case is case 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# discretization\n",
    "# k is the number of class,as the problem is a binary problem (0,1)\n",
    "# p is the probability of 0 and q is the probability of 1\n",
    "\n",
    "# calculate the entropy value and the ratio is considered\n",
    "def entropy_value(a,b,c,d,p,q,k,n):\n",
    "    entropy_v = 0\n",
    "    for i in range(k):\n",
    "        # as log2 will return nan for zero value and causing error in the iteration,\n",
    "        # the entropy is directly set to 0\n",
    "        if p[0,i] == 0: # entropy of a specific class with zero binary value \n",
    "            e_v_p = 0\n",
    "        else:\n",
    "            e_v_p = -p[0,i]*np.log2(p[0,i])\n",
    "        if q[0,i] == 0: # enreopy of a specific class with one binary value\n",
    "            e_v_n = 0\n",
    "        else:\n",
    "            e_v_n = -q[0,i]*np.log2(q[0,i])\n",
    "        \n",
    "        # dividing the ratio\n",
    "        if i == 0:\n",
    "            entropy_v = entropy_v + ((e_v_p + e_v_n)*a.shape[0]/n)\n",
    "        elif i == 1:\n",
    "            entropy_v = entropy_v + ((e_v_p + e_v_n)*b.shape[0]/n)\n",
    "        elif i == 2:\n",
    "            entropy_v = entropy_v + ((e_v_p + e_v_n)*c.shape[0]/n)\n",
    "        else:\n",
    "            entropy_v = entropy_v + ((e_v_p + e_v_n)*d.shape[0]/n)\n",
    "    return entropy_v\n",
    "\n",
    "# calculate the probabilities for each binary value in each class\n",
    "def p_q_probability(a,b,c,d,k):\n",
    "    p = np.zeros([1,k])\n",
    "    q = np.zeros([1,k])\n",
    "    for i in range(k):\n",
    "        if i == 0: # probability value of class a\n",
    "            q[0,i] = np.count_nonzero(a)/a.shape[0]\n",
    "            p[0,i] = 1 - q[0,i]\n",
    "        elif i == 1: # probability value of class b\n",
    "            q[0,i] = np.count_nonzero(b)/b.shape[0]\n",
    "            p[0,i] = 1 - q[0,i]\n",
    "        elif i == 2: # probability value of class c\n",
    "            q[0,i] = np.count_nonzero(c)/c.shape[0]\n",
    "            p[0,i] = 1 - q[0,i]\n",
    "        else: # probability value of class d\n",
    "            q[0,i] = np.count_nonzero(d)/d.shape[0]\n",
    "            p[0,i] = 1 - q[0,i]\n",
    "    return p,q\n",
    "\n",
    "# case 1\n",
    "a = np.array([0])\n",
    "b = np.array([0,1])\n",
    "c = np.array([1,1,0,0,1])\n",
    "d = np.array([0,0])\n",
    "n = a.shape[0]+b.shape[0]+c.shape[0]+d.shape[0] # total number of binar value\n",
    "k = 4 # total number of class\n",
    "p1,q1 = p_q_probability(a,b,c,d,k)\n",
    "case1_entropy = entropy_value(a,b,c,d,p1,q1,k,n)\n",
    "\n",
    "# case 2\n",
    "a = np.array([0,0,1])\n",
    "b = np.array([1,1,0])\n",
    "c = np.array([0,1,0])\n",
    "d = np.array([0])\n",
    "n = a.shape[0]+b.shape[0]+c.shape[0]+d.shape[0]\n",
    "k = 4\n",
    "p2,q2 = p_q_probability(a,b,c,d,k)\n",
    "case2_entropy = entropy_value(a,b,c,d,p2,q2,k,n)\n",
    "\n",
    "# case 3\n",
    "a = np.array([0])\n",
    "b = np.array([0,1,1,1,0,0,1])\n",
    "c = np.array([0])\n",
    "d = np.array([0])\n",
    "n = a.shape[0]+b.shape[0]+c.shape[0]+d.shape[0]\n",
    "k = 4\n",
    "p3,q3 = p_q_probability(a,b,c,d,k)\n",
    "case3_entropy = entropy_value(a,b,c,d,p3,q3,k,n)\n",
    "\n",
    "print('Case 1 Entropy:',case1_entropy)\n",
    "print('Case 2 Entropy:',case2_entropy)\n",
    "print('Case 3 Entropy:',case3_entropy)\n",
    "Entropies = np.array([case1_entropy,case2_entropy,case3_entropy])\n",
    "\n",
    "# find the best clustering result\n",
    "best_case = np.argmin(Entropies)+1\n",
    "print('The best clustering case is case',best_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The entropy of the test case is 0.8\n"
     ]
    }
   ],
   "source": [
    "# to verify my program, the data below is created for testing\n",
    "# testing case\n",
    "a = np.array([0,0])\n",
    "b = np.array([0,1,0,1])\n",
    "c = np.array([0,1])\n",
    "d = np.array([1,0])\n",
    "n = a.shape[0]+b.shape[0]+c.shape[0]+d.shape[0]\n",
    "k = 4\n",
    "pts,qts = p_q_probability(a,b,c,d,k)\n",
    "casets_entropy = entropy_value(a,b,c,d,pts,qts,k,n)\n",
    "print('The entropy of the test case is',casets_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
